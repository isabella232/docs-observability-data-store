---
title: Installing Observability Data Store for PCF
owner: Primus
---

This topic describes how to install and configure Observability Data Store for Pivotal Cloud Foundry (PCF). For a list of compatible Ops Manager, Pivotal Application Service (PAS)  and Pivotal Container Service (PKS) versions, see [Product Snapshot](index.html#snapshot).

##<a id='install'></a> Install Observability Data Store for PCF

1. Download the product file from [Pivotal Network](https://network.pivotal.io/products/observability_datastore_pcf).

1. Navigate to the Ops Manager Installation Dashboard and click **Import a Product** to upload the product file.

1. Under the **Import a Product** button, click **+** next to the version number of Observability Data Store for PCF.
This adds the tile to your staging area.

##<a id='configure'></a> Configure Observability Data Store for PCF

To start using Observability Data Store for PCF, you need to configure the Observability Data Store for PCF tile.

### <a id='observability-data-store-tile'></a> Configure the Observability Data Store for PCF Tile

To configure the Observability Data Store for PCF tile, perform the following steps:

1. Click the **Observability Data Store for PCF** tile on the Ops Manager Installation Dashboard.
1. Navigate to **Assign AZs and Networks** and do the following:
    1. Select an Availability Zone (AZ) for placing singleton jobs.
    1. Select one or more AZs for balancing other jobs.

		<p class="note"><strong>Note</strong>: To create a highly available environment, Pivotal recommends selecting multiple AZs.</p>

    1. Select **Network** for installing Observability Data Store for PCF.
    1. Click **Save**.

1. Navigate to **Prometheus Configuration** and do the following:
    1. Optional: Modify the **Scrape Interval** as desired. This controls the frequency at which Prometheus scrapes its targets for metrics.

1. Return to the Ops Manager Installation Dashboard and click **Apply Changes**.

1. (Optional) Grafana is deployed on port 3000. A named route to Grafana can be configured in your IaaS or a native IaaS load balancer can be used.

### <a id='observability-data-store-tile'></a> (Optional) Backing Up Observability Data Store for PCF

Observability Data Store for PCF supports (Bosh Backup and Restore)[https://docs.pivotal.io/pivotalcf/2-4/customizing/backup-restore/index.html] functionality.
We recommend running nightly backups via a Concourse pipeline job like the one below:

```yaml
---
resource_types:
  - name: gcs-resource
    type: docker-image
    source:
      repository: frodenas/gcs-resource

  - name: pivnet
    type: docker-image
    source:
      repository: pivotalcf/pivnet-resource
      tag: latest-final

resources:
  - name: bbr-release
    type: pivnet
    source:
      api_token: ((pivnet-refresh-token))
      product_slug: p-bosh-backup-and-restore

  - name: bbr-pipeline-tasks-repo
    type: git
    source:
      uri: https://github.com/pivotal-cf/bbr-pcf-pipeline-tasks.git
      branch: master
      tag_filter: v1.0.0

  - name: bbr-docker
    type: docker-image
    source:
      repository: cloudfoundrylondon/bbr-pipeline
      tag: final

  - name: nightly
    type: time
    source:
      interval: 24h
      start: 22:00
      stop: 00:00
      location: America/Denver

  - name: ods-backup-bucket
    type: gcs-resource
    source:
      bucket: ((gcs-bucket-name))
      json_key: ((service-account-json))
      regexp: ((gcs-directory))/ods-backup-(.*).tar

jobs:
  - name: trigger-backup
    plan:
      - put: nightly

  - name: nightly-backup
    plan:
      - aggregate:
        - get: nightly
          trigger: true
        - get: bbr-docker
        - get: bbr-release
        - get: bbr-pipeline-tasks-repo
      - task: extract-binary
        file: bbr-pipeline-tasks-repo/tasks/extract-bbr-binary/task.yml
      - task: run-backup
        image: bbr-docker
        config:
          platform: linux

          inputs:
            - name: binary
            - name: bbr-pipeline-tasks-repo

          outputs:
            - name: ods-backup-artifact

          params:
            OPSMAN_URL: ((opsman-url))
            OPSMAN_USERNAME: ((opsman-user.username))
            OPSMAN_PASSWORD: ((opsman-user.password))
            OPSMAN_PRIVATE_KEY: ((ops-man-ssh-key.private_key))

          run:
            path: /bin/bash
            args:
              - -c
              - |
                #!/usr/bin/env bash

                set -eu

                scripts="${PWD}/bbr-pipeline-tasks-repo/scripts"

                export CLIENT_ID=
                # shellcheck disable=SC1090
                source "${scripts}/export-director-metadata"

                om_cmd curl -p /api/v0/deployed/products > deployed_products.json
                DEPLOYMENT_NAME=$(jq -r '.[] | select(.type == "p-observability-data-store") | .guid' "deployed_products.json")
                export DEPLOYMENT_NAME

                pushd ods-backup-artifact
                  ${scripts}/deployment-backup
                  tar -cvf ods-backup-$(date +%Y.%m.%d.%H.%M.%S).tar -- *
                popd

      - put: ods-backup-bucket
        params:
          file: ods-backup-artifact/ods-backup-*.tar
```

### <a id='observability-data-store-tile'></a> (Optional) Restoring Observability Data Store for PCF from a BBR Backup
If you are running nightly backups, you have the ability to restore the Prometheus data using Bosh Backup and Restore. 
Be aware that this will delete any existing data on all Prometheus VMs and restore them to when the backup was taken.

To restore, run the following commands:

```
mkdir -p $PATH_TO_DEPLOYMENT_BACKUP
tar xvf ods-backup-*.tar -C $PATH_TO_DEPLOYMENT_BACKUP
bbr deployment \
  --target $BOSH_TARGET \
  --username $BOSH_CLIENT \
  --password $BOSH_PASSWORD \
  --deployment $OBSERVABILITY_DATA_STORE_DEPLOYMENT_NAME \
  --ca-cert $PATH_TO_BOSH_SERVER_CERTIFICATE \
  restore \
  --artifact-path $PATH_TO_DEPLOYMENT_BACKUP
```

##<a id='install'></a> (Optional) Install Telegraf for Firehose Metrics

If Firehose metrics are desired then Telegraf can be installed on each foundation with Pivotal Application Service.
We recommend CF pushing Telegraf using the binary provided on [PivNet](https://network.pivotal.io/products/observability_datastore_pcf).

1. Download the Telegraf binary and associated `telegraf.conf`
2. Edit the `telegraf.conf`.  Details for doing so can be found here: [Telegraf Documentation](https://docs.influxdata.com/telegraf/v1.10/administration/configuration/)
3. Create certificates for connecting to the Reverse Log Proxy endpoint.
  a. Get the Ops Manager CA Certificate and copy it to a file named `loggregator_ca.crt` using `om certificate-authorities`
  b. Generate certificates to communicate with Reverse Log Proxy over mTLS using `om generate-certificate --domains reverse-log-proxy.service.cf.internal`
4. CF Push Telegraf to the desired foundation
  a. Place the telegraf binary, the `telegraf.conf` and the three certficates in a folder and navigate to that folder.
  b. Target the foundation to be monitored and run `cf push telegraf -b binary_buildpack -c "./telegraf -config telegraf.conf"`
5. Add a scrape config job to Observability Data Store for the new telegraf. Example:
```
- job_name: telegraf
  metrics_path: /metrics
  scheme: https
  static_configs:
  - targets:
    - "telegraf.apps.<domain>"
```
